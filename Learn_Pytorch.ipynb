{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMvMZL2euYowQK8qswe7SrI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KalharaBatangala/Learn-pytorch/blob/main/Learn_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "xXlzAWrSHTRP"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pytorch basics**"
      ],
      "metadata": {
        "id": "2sJ9vu-yz14b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrkpTvX7Hhz2",
        "outputId": "f9e99e70-7081-4cbb-e893-c31861de8fd6"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.4.1+cu121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mylist = [[1,2,3],[4,5,6]]    # this is a typical python list.\n",
        "                              # Neither a numpy array nor a tensor\n",
        "\n",
        "#numpy array\n",
        "np1 = np.random.rand(3,5,5) # Random.rand no [] brackets\n",
        "np1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtJxsRTEHyGv",
        "outputId": "09fed7d9-f563-4e01-cb83-05df2f35931a"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0.39495268, 0.83815573, 0.21610509, 0.66351101, 0.45895054],\n",
              "        [0.84319445, 0.20499561, 0.37202374, 0.58551588, 0.40703247],\n",
              "        [0.24806147, 0.01977322, 0.57795453, 0.28133574, 0.48385929],\n",
              "        [0.9215345 , 0.89179061, 0.43109999, 0.52859502, 0.03037878],\n",
              "        [0.62030068, 0.79748269, 0.71492142, 0.74173978, 0.86629411]],\n",
              "\n",
              "       [[0.22531842, 0.59981654, 0.03443702, 0.72987974, 0.34995965],\n",
              "        [0.21782257, 0.91776887, 0.17687615, 0.65933108, 0.51148224],\n",
              "        [0.78562531, 0.04731341, 0.50257556, 0.85535337, 0.3180482 ],\n",
              "        [0.85302408, 0.70539444, 0.5751464 , 0.3048853 , 0.6394438 ],\n",
              "        [0.25621318, 0.32255039, 0.87396097, 0.58223039, 0.82151314]],\n",
              "\n",
              "       [[0.25864141, 0.83390979, 0.65695625, 0.36558913, 0.25101023],\n",
              "        [0.69447067, 0.7034484 , 0.89733058, 0.09149562, 0.90816662],\n",
              "        [0.15880646, 0.81671376, 0.88580967, 0.67381947, 0.67408133],\n",
              "        [0.00674241, 0.49366765, 0.8150061 , 0.96317565, 0.54446506],\n",
              "        [0.5408165 , 0.94097869, 0.85770349, 0.14869018, 0.37359349]]])"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np2 = 100 * np.random.rand(2,3)\n",
        "np2 = np.array(np2, dtype=int)\n",
        "np2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRRXdPbDWP7I",
        "outputId": "918d6ed4-0286-4041-9b28-c6f90ae9c69b"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[19, 62, 25],\n",
              "       [57, 64, 27]])"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test1 = np.random.rand(4) * 10\n",
        "test1.reshape(2,2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Tp6s6hBg2Ra",
        "outputId": "03740dee-1512-495b-d368-fc3968773081"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[7.05593342, 8.73151255],\n",
              "       [9.71734567, 4.23189453]])"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test2 = np.array([1,2,3,4,5,6])\n",
        "test2\n",
        "\n",
        "my_device = torch.cpu.current_device()\n",
        "my_device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "vILZGxupmiGa",
        "outputId": "5e7aa8f1-17d2-4a0a-ced0-69fb174f7688"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using ones and Zeros\n",
        "ones = np.ones([2,3], dtype=int)  # Must need [] brackets in ones & zeros.\n",
        "ones                              # dtype can be specified in np.ones and np.zeros"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwdPQUKc39nL",
        "outputId": "e5c6c344-1177-4cdc-dfac-3185fb1e05de"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 1, 1],\n",
              "       [1, 1, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np1.dtype)   # Random has no arguement as dtype\n",
        "                   # Therefore always dtype=float64 (default)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55E_HSgVKgV9",
        "outputId": "061d2c8d-39cc-4108-eeeb-35fc56614967"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ar_ones = torch.ones(5)\n",
        "print(ar_ones)\n",
        "print('No. of elements : ', torch.numel(ar_ones))\n",
        "torch.is_tensor(ar_ones)    # check whethr a tensor\n",
        "torch.is_storage(ar_ones)   # not an storage - False\n",
        "torch.is_nonzero(ar_ones[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNaNusC5AzZ8",
        "outputId": "445b58d3-c8ab-4cf2-cfb0-d13645fad045"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1., 1., 1.])\n",
            "No. of elements :  5\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#torch.is_nonzero(ar_ones)\n",
        "# RuntimeError                              Traceback (most recent call last)\n",
        "# <ipython-input-30-011fd7f163f7> in <cell line: 1>()\n",
        "# ----> 1 torch.is_nonzero(ar_ones)\n",
        "\n",
        "# RuntimeError: Boolean value of Tensor with more than one value is ambiguous"
      ],
      "metadata": {
        "id": "Ti5JQX9HGDAb"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_2d = torch.rand(3,4)   # Doesn't matter whether [] is present or not in TENSOR\n",
        "tensor_2d\n",
        "\n",
        "tensor2d = torch.rand([3,4])\n",
        "print('tensor_2d\\n', tensor2d * 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUDXzbPEOXf5",
        "outputId": "b0cfc9dc-8242-4c3d-fc9b-4709c2559902"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor_2d\n",
            " tensor([[4.8273, 3.0898, 6.2797, 6.2945],\n",
            "        [7.2349, 0.5989, 7.2704, 5.9118],\n",
            "        [0.9042, 2.7294, 3.5168, 6.7117]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testing = torch.tensor([1,2.,3],  requires_grad=True, device=torch.device('cpu'))\n",
        "threads = torch.get_num_threads()\n",
        "print('Number of threads :',threads)\n",
        "testing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yIMNUUeeQY5",
        "outputId": "0ed694ae-4b80-4725-b15e-03a5d1e5c52c"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of threads : 1\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 2., 3.], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "check_grad = torch.is_grad_enabled()\n",
        "print(check_grad)\n",
        "torch.no_grad()\n",
        "print(torch.is_grad_enabled())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEdmsJqOgqkh",
        "outputId": "3de4b05b-ec9d-4ce3-c6f6-26b0a0498cd3"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_3d = torch.zeros(2,3,4)\n",
        "print(tensor_3d.dtype)\n",
        "tensor_3d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KV6c9N_OuET",
        "outputId": "226cf0cc-d6c6-46bc-aaa0-892f007742f9"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float32\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a tensor out of numpy array\n",
        "mytensor = torch.tensor(np1)\n",
        "mytensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0p5zTqePijC",
        "outputId": "3dac4a29-f3a5-4378-ccaa-eae69f7c98c6"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.3950, 0.8382, 0.2161, 0.6635, 0.4590],\n",
              "         [0.8432, 0.2050, 0.3720, 0.5855, 0.4070],\n",
              "         [0.2481, 0.0198, 0.5780, 0.2813, 0.4839],\n",
              "         [0.9215, 0.8918, 0.4311, 0.5286, 0.0304],\n",
              "         [0.6203, 0.7975, 0.7149, 0.7417, 0.8663]],\n",
              "\n",
              "        [[0.2253, 0.5998, 0.0344, 0.7299, 0.3500],\n",
              "         [0.2178, 0.9178, 0.1769, 0.6593, 0.5115],\n",
              "         [0.7856, 0.0473, 0.5026, 0.8554, 0.3180],\n",
              "         [0.8530, 0.7054, 0.5751, 0.3049, 0.6394],\n",
              "         [0.2562, 0.3226, 0.8740, 0.5822, 0.8215]],\n",
              "\n",
              "        [[0.2586, 0.8339, 0.6570, 0.3656, 0.2510],\n",
              "         [0.6945, 0.7034, 0.8973, 0.0915, 0.9082],\n",
              "         [0.1588, 0.8167, 0.8858, 0.6738, 0.6741],\n",
              "         [0.0067, 0.4937, 0.8150, 0.9632, 0.5445],\n",
              "         [0.5408, 0.9410, 0.8577, 0.1487, 0.3736]]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a tensor with specific data type\n",
        "mytensor = torch.zeros([2,3],dtype=torch.int64)\n",
        "mytensor\n",
        "\n",
        "cuda0 = torch.device('cuda:0')\n",
        "print(mytensor)\n",
        "cuda0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-RM9tCwddrr",
        "outputId": "74f40bfd-106a-4e85-b487-229dd5e46114"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 0, 0],\n",
            "        [0, 0, 0]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "  #print('No cuda device found')\n",
        "  #print(torch.cpu.current_device())\n",
        "  print(torch.cuda.get_device_name())\n",
        "else:\n",
        "  print('Current device :',torch.cpu.current_device())\n",
        "  print('CPU available :',torch.cpu.is_available())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OcAtUleIT6Hd",
        "outputId": "5a2156a9-8167-4507-9c54-cb22da5d7790"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current device : cpu\n",
            "CPU available : True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "  torch.ones([4,4], dtype=torch.float64, device=cuda0)\n",
        "else:\n",
        "  print('no GPU found')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYiZHJqJRSFt",
        "outputId": "ef59be4b-7a35-4ddc-c41f-786816cd3110"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "no GPU found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Content can be accessed and modified using slice and indexing"
      ],
      "metadata": {
        "id": "hAV3p6RrUuWY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "r = torch.tensor([[1,2,3], [4,5,6]])\n",
        "y = np.random.rand(2,3)\n",
        "print(r[1][0])\n",
        "print(y)\n",
        "print(y[1][1])\n",
        "z = torch.tensor(y)\n",
        "\n",
        "print(z[1][1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mMuWvHt0biq",
        "outputId": "c7a899ec-1d2f-4cbe-e016-8c54ae36f1f1"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(4)\n",
            "[[0.92663695 0.91398391 0.79986664]\n",
            " [0.44383698 0.79019601 0.44914811]]\n",
            "0.7901960085286751\n",
            "tensor(0.7902, dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "x = torch.tensor([[1,2,3], [4,5,6]])\n",
        "y = np.random.rand(2,3)\n",
        "print(x[1][0])\n",
        "print(y)\n",
        "print(y[1][1])\n",
        "z = torch.tensor(y)\n",
        "\n",
        "print(z[1][1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Iy7nGwEeTTf",
        "outputId": "da2e1d9d-b9fc-45ba-ed72-10fbefd8c001"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(4)\n",
            "[[0.53688903 0.41272772 0.72920852]\n",
            " [0.21424931 0.22231966 0.57440733]]\n",
            "0.2223196613758115\n",
            "tensor(0.2223, dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Torch.tensor.item() :  get a Python number from a tensor containing a **single value**"
      ],
      "metadata": {
        "id": "Yd4El915DagA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([[1]])\n",
        "x\n",
        "x.item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVllzgNJDdfa",
        "outputId": "da574083-dc6a-44e9-88ad-08bfb5c6ab39"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tnsr = torch.tensor([[1,-1],[1,1]],dtype=torch.float64, requires_grad=True)\n",
        "tnsr\n",
        "\n",
        "          # OR #\n",
        "tnsr = torch.tensor([[1.,-1.],[1.,1.]], requires_grad=True)\n",
        "tnsr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTXOW_LbEDar",
        "outputId": "bf56ec68-2ae8-4644-b03b-e33bf1d48fa1"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1., -1.],\n",
              "        [ 1.,  1.]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out = tnsr.pow(2).sum()\n",
        "out.backward()\n",
        "tnsr.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7sFoX5sE_2Q",
        "outputId": "a78705a5-d67d-46fd-a4df-d8aca7018eb0"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 2., -2.],\n",
              "        [ 2.,  2.]])"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#gpu = torch.cpu.current_device()\n",
        "cuda = torch.cuda.is_available()\n",
        "if cuda == True:\n",
        "  print('cuda is available')\n",
        "  print('current device : ', torch.cuda.current_device())\n",
        "  print('device count : ', torch.cuda.device_count())\n",
        "  print('device name is : ', torch.cuda.get_device_name())\n",
        "  device = torch.device('cuda:0')\n",
        "  print('device properties : ', torch.cuda.get_device_properties(device))\n",
        "#print('Power drawn by GPU : ', torch.cuda.power_draw(device))\n"
      ],
      "metadata": {
        "id": "Cv3pzJ51G_6Q"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#gpu\n",
        "#gpu = torch.device('cuda:0')\n",
        "#gpu"
      ],
      "metadata": {
        "id": "yXxeLfj6Jbdj"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Basic Math Operations**"
      ],
      "metadata": {
        "id": "vlWH0kzJuvgS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_a = torch.tensor([1,2,3,4])\n",
        "tensor_b = torch.tensor([4,5,6,7])\n",
        "\n",
        "print(torch.add(tensor_a, tensor_b))\n",
        "print(torch.mul(tensor_a , tensor_b))\n",
        "print(torch.divide(tensor_a , tensor_b))\n",
        "print(torch.remainder(tensor_b, tensor_a))\n",
        "print(torch.pow(tensor_a, tensor_b))"
      ],
      "metadata": {
        "id": "Ge6QiLAUKkaS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1dd6780-f85a-4f6b-c6f6-de08e9f4e37a"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 5,  7,  9, 11])\n",
            "tensor([ 4, 10, 18, 28])\n",
            "tensor([0.2500, 0.4000, 0.5000, 0.5714])\n",
            "tensor([0, 1, 0, 3])\n",
            "tensor([    1,    32,   729, 16384])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tens = torch.tensor([12,4,7])\n",
        "tens\n",
        "tens.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLPVAGOlauGq",
        "outputId": "afb0b85f-92e9-4019-c94e-b45b6ab18185"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3])"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_tensor = torch.randn(3)\n",
        "print(my_tensor)\n",
        "my_tensor = torch.mul(my_tensor, 100)\n",
        "my_tensor = torch.abs(my_tensor)    # Get the absolute value\n",
        "# my_tensor = torch.mul(my_tensor, 100)\n",
        "# my_tensor\n",
        "print('Rounded values : ',torch.round(my_tensor))\n",
        "torch.max(my_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9patke57IvD",
        "outputId": "372001de-e7e0-4d13-990e-948f6885f5e8"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.2566,  0.4819,  0.1692])\n",
            "Rounded values :  tensor([26., 48., 17.])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(48.1878)"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prod_this = torch.tensor([1,2,3,4,5])\n",
        "torch.prod(prod_this)\n",
        "seven20 = torch.arange(1,7)\n",
        "seven20\n",
        "print(torch.prod(seven20))\n",
        "\n",
        "# count non-zero\n",
        "print(torch.count_nonzero(prod_this))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgxM1pYmDkl4",
        "outputId": "7f480f54-0a19-468e-e480-8bd92a54d6af"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(720)\n",
            "tensor(5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sort"
      ],
      "metadata": {
        "id": "ffVHuVXPE-15"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.sort(prod_this, descending=False)     #descending=False we can change it to True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmsYhcCkFA0_",
        "outputId": "cb437adf-82f0-4a79-d4bc-e3e1c4e192c1"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.return_types.sort(\n",
              "values=tensor([1, 2, 3, 4, 5]),\n",
              "indices=tensor([0, 1, 2, 3, 4]))"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.tensor([1,2,3,4,5,6]).reshape(2,3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjasuAei1me5",
        "outputId": "ba2f94eb-2623-4ec3-cbf0-d96281014725"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3],\n",
              "        [4, 5, 6]])"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "  torch.cuda.get_device_properties(torch.cuda.get_device_name)\n",
        "\n",
        "  torch.cuda.get_device_capability(torch.cuda.get_device_name)\n",
        "  torch.cuda.is_available()\n",
        "  torch.cuda.is_initialized()\n",
        "  print('memory allocated : ',torch.cuda.memory_allocated())\n",
        "  print('memory usage: ', torch.cuda.memory_cached)\n",
        "  torch.cuda.power_draw"
      ],
      "metadata": {
        "id": "yGF-eb7qtFZR"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor(torch.rand(50))\n",
        "\n",
        "shape = torch.reshape(a, (5,10))\n",
        "shape.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhYdnPDFvH-H",
        "outputId": "35f91ad3-b15d-4430-d8bf-40e13cd003d9"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-121-0d7fd5271b5f>:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  a = torch.tensor(torch.rand(50))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CPU**"
      ],
      "metadata": {
        "id": "66ay4-s70vNi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cpu.current_device()\n",
        "torch.cpu.device_count"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "raqqy_3j0yyK",
        "outputId": "de0f9394-63e8-4086-9fc0-22883d9e6181"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function torch.cpu.device_count() -> int>"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>torch.cpu.device_count</b><br/>def device_count() -&gt; int</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/torch/cpu/__init__.py</a>Returns number of CPU devices (not cores). Always 1.\n",
              "\n",
              "N.B. This function only exists to facilitate device-agnostic code</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 148);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_arr = torch.tensor([[15,12],[12,8]])\n",
        "print(y_arr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEugj3VRJ-NC",
        "outputId": "b2999946-5d8b-42b5-e53c-59957829f98b"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[15, 12],\n",
            "        [12,  8]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor"
      ],
      "metadata": {
        "id": "LsdRQJvFlkMj"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download training data from open datasets.\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")\n",
        "\n",
        "# Download test data from open datasets.\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYnbGm0XloSa",
        "outputId": "1b503d8d-aa62-4644-faa7-07d3468ed24f"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:05<00:00, 4996639.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 136701.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:06<00:00, 683032.84it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 14708635.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "# Create data loaders.\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "for X, y in test_dataloader:\n",
        "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
        "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCSbFkvql4Fd",
        "outputId": "eea3e015-4c12-4b7f-8260-64325dfbc95c"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
            "Shape of y: torch.Size([64]) torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating Models**"
      ],
      "metadata": {
        "id": "bnXQAjsQmCdT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get cpu, gpu or mps device for training.\n",
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "# Define model\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "model = NeuralNetwork().to(device)    #move to GPU\n",
        "print(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGhPFZ0gmDzj",
        "outputId": "56940038-49e2-418f-b632-71a8513b625b"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**!!! Pytorch Practice Session Covered all the necessary basic operations in Pytorch Library  !!!**"
      ],
      "metadata": {
        "id": "giAA-aybNEel"
      }
    }
  ]
}