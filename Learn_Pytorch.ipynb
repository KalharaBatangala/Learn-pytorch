{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMywJzYzkLZ3HpyE5L5Sao2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KalharaBatangala/Learn-pytorch/blob/main/Learn_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xXlzAWrSHTRP"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pytorch basics**"
      ],
      "metadata": {
        "id": "2sJ9vu-yz14b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrkpTvX7Hhz2",
        "outputId": "743807f4-b6bd-4fd0-e7ce-43fbfdd1cc60"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.4.1+cu121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mylist = [[1,2,3],[4,5,6]]\n",
        "\n",
        "#numpy array\n",
        "np1 = np.random.rand(3,5,5) # Random.rand no [] brackets\n",
        "np1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtJxsRTEHyGv",
        "outputId": "7e9fe2dd-1306-46b0-bfa8-e86f460cb509"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0.43964009, 0.49364935, 0.35326777, 0.365042  , 0.42704762],\n",
              "        [0.64244857, 0.51534889, 0.10489257, 0.44521648, 0.3836991 ],\n",
              "        [0.90840217, 0.70173556, 0.81278947, 0.37815286, 0.05592542],\n",
              "        [0.08655668, 0.00305081, 0.85854099, 0.57720618, 0.26042843],\n",
              "        [0.02918901, 0.46460569, 0.51664208, 0.04485946, 0.73849502]],\n",
              "\n",
              "       [[0.20829142, 0.23795253, 0.51481511, 0.08710223, 0.87895792],\n",
              "        [0.89925622, 0.20111599, 0.27711792, 0.27733896, 0.31968132],\n",
              "        [0.18892444, 0.40874301, 0.14009903, 0.18440064, 0.79580007],\n",
              "        [0.69783442, 0.29279392, 0.81836366, 0.00409571, 0.83555723],\n",
              "        [0.38195129, 0.88022893, 0.85761847, 0.41379457, 0.52066184]],\n",
              "\n",
              "       [[0.49197493, 0.82696491, 0.43573354, 0.56342373, 0.15320451],\n",
              "        [0.21006536, 0.76380526, 0.38506228, 0.06308692, 0.4234943 ],\n",
              "        [0.12361332, 0.29745894, 0.0898349 , 0.09770054, 0.96377387],\n",
              "        [0.08697015, 0.25248038, 0.41326694, 0.27561093, 0.77051774],\n",
              "        [0.87954203, 0.90643253, 0.42228582, 0.80623506, 0.67657701]]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using ones and Zeros\n",
        "ones = np.ones([2,3], dtype=int)  # Must need [] brackets in ones & zeros.\n",
        "ones                              # dtype can be specified in np.ones and np.zeros"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwdPQUKc39nL",
        "outputId": "caf1c801-159a-4ee3-97a1-ab242b8cbe09"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 1, 1],\n",
              "       [1, 1, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np1.dtype)   # Random has no arguement as dtype\n",
        "                   # Therefore always dtype=float64 (default)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55E_HSgVKgV9",
        "outputId": "86ed4545-6ef5-47ce-97a2-1a8196bb7f6a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ar_ones = torch.ones(5)\n",
        "print(ar_ones)\n",
        "print('No. of elements : ', torch.numel(ar_ones))\n",
        "torch.is_tensor(ar_ones)    # check whethr a tensor\n",
        "torch.is_storage(ar_ones)   # not an storage - False\n",
        "torch.is_nonzero(ar_ones[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNaNusC5AzZ8",
        "outputId": "8a1a0fc0-5768-4ab2-d209-21d6869bac75"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1., 1., 1.])\n",
            "No. of elements :  5\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#torch.is_nonzero(ar_ones)\n",
        "# RuntimeError                              Traceback (most recent call last)\n",
        "# <ipython-input-30-011fd7f163f7> in <cell line: 1>()\n",
        "# ----> 1 torch.is_nonzero(ar_ones)\n",
        "\n",
        "# RuntimeError: Boolean value of Tensor with more than one value is ambiguous"
      ],
      "metadata": {
        "id": "Ti5JQX9HGDAb"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_2d = torch.rand(3,4)   # Doesn't matter whether [] is present or not in TENSOR\n",
        "tensor_2d\n",
        "\n",
        "tensor2d = torch.rand([3,4])\n",
        "print('tensor_2d\\n', tensor2d * 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUDXzbPEOXf5",
        "outputId": "371ef6dd-2703-409c-ab32-249b03afab59"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor_2d\n",
            " tensor([[7.6257, 5.5807, 5.1118, 4.9280],\n",
            "        [3.6901, 0.0955, 4.9299, 1.7102],\n",
            "        [3.4505, 9.4647, 8.6870, 4.1594]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testing = torch.tensor([1,2.,3],  requires_grad=True, device=torch.device('cpu'))\n",
        "threads = torch.get_num_threads()\n",
        "print('Number of threads :',threads)\n",
        "testing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yIMNUUeeQY5",
        "outputId": "858e61f9-9b40-45dd-8600-6a9ef3c934fb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of threads : 1\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 2., 3.], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "check_grad = torch.is_grad_enabled()\n",
        "print(check_grad)\n",
        "torch.no_grad()\n",
        "print(torch.is_grad_enabled())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEdmsJqOgqkh",
        "outputId": "98647adf-7e93-4bc9-c831-92012ed3d2d0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_3d = torch.zeros(2,3,4)\n",
        "print(tensor_3d.dtype)\n",
        "tensor_3d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KV6c9N_OuET",
        "outputId": "74b35f47-753b-44c8-fe0d-fee9c1271dc1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float32\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a tensor out of numpy array\n",
        "mytensor = torch.tensor(np1)\n",
        "mytensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0p5zTqePijC",
        "outputId": "0395dd85-608e-40ec-e5f7-3fa1ef7986b1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.4396, 0.4936, 0.3533, 0.3650, 0.4270],\n",
              "         [0.6424, 0.5153, 0.1049, 0.4452, 0.3837],\n",
              "         [0.9084, 0.7017, 0.8128, 0.3782, 0.0559],\n",
              "         [0.0866, 0.0031, 0.8585, 0.5772, 0.2604],\n",
              "         [0.0292, 0.4646, 0.5166, 0.0449, 0.7385]],\n",
              "\n",
              "        [[0.2083, 0.2380, 0.5148, 0.0871, 0.8790],\n",
              "         [0.8993, 0.2011, 0.2771, 0.2773, 0.3197],\n",
              "         [0.1889, 0.4087, 0.1401, 0.1844, 0.7958],\n",
              "         [0.6978, 0.2928, 0.8184, 0.0041, 0.8356],\n",
              "         [0.3820, 0.8802, 0.8576, 0.4138, 0.5207]],\n",
              "\n",
              "        [[0.4920, 0.8270, 0.4357, 0.5634, 0.1532],\n",
              "         [0.2101, 0.7638, 0.3851, 0.0631, 0.4235],\n",
              "         [0.1236, 0.2975, 0.0898, 0.0977, 0.9638],\n",
              "         [0.0870, 0.2525, 0.4133, 0.2756, 0.7705],\n",
              "         [0.8795, 0.9064, 0.4223, 0.8062, 0.6766]]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a tensor with specific data type\n",
        "mytensor = torch.zeros([2,3],dtype=torch.int64)\n",
        "mytensor\n",
        "\n",
        "cuda0 = torch.device('cuda:0')\n",
        "print(mytensor)\n",
        "cuda0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-RM9tCwddrr",
        "outputId": "37a258c9-4d56-4f20-a992-c37ac7abb213"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 0, 0],\n",
            "        [0, 0, 0]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.ones([4,4], dtype=torch.float64, device=cuda0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYiZHJqJRSFt",
        "outputId": "4c4c4d81-6da1-4e9d-820c-30621b50d886"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.]], device='cuda:0', dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Content can be accessed and modified using slice and indexing"
      ],
      "metadata": {
        "id": "hAV3p6RrUuWY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "r = torch.tensor([[1,2,3], [4,5,6]])\n",
        "y = np.random.rand(2,3)\n",
        "print(r[1][0])\n",
        "print(y)\n",
        "print(y[1][1])\n",
        "z = torch.tensor(y)\n",
        "\n",
        "print(z[1][1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mMuWvHt0biq",
        "outputId": "0cfde328-af87-47c8-c427-d98a627631de"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(4)\n",
            "[[0.1188192  0.55130186 0.87172378]\n",
            " [0.80162719 0.79078104 0.74249843]]\n",
            "0.7907810398712574\n",
            "tensor(0.7908, dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "x = torch.tensor([[1,2,3], [4,5,6]])\n",
        "y = np.random.rand(2,3)\n",
        "print(x[1][0])\n",
        "print(y)\n",
        "print(y[1][1])\n",
        "z = torch.tensor(y)\n",
        "\n",
        "print(z[1][1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Iy7nGwEeTTf",
        "outputId": "1a6d0a7d-a572-4899-8759-fedd916a6460"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(4)\n",
            "[[0.51807096 0.23716001 0.53519   ]\n",
            " [0.79894202 0.1640777  0.82753894]]\n",
            "0.1640777042956898\n",
            "tensor(0.1641, dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Torch.tensor.item() :  get a Python number from a tensor containing a **single value**"
      ],
      "metadata": {
        "id": "Yd4El915DagA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([[1]])\n",
        "x\n",
        "x.item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVllzgNJDdfa",
        "outputId": "6de7e670-2a7d-4f6e-e6e2-0dedbe96ea7f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tnsr = torch.tensor([[1,-1],[1,1]],dtype=torch.float64, requires_grad=True)\n",
        "tnsr\n",
        "\n",
        "          # OR #\n",
        "tnsr = torch.tensor([[1.,-1.],[1.,1.]], requires_grad=True)\n",
        "tnsr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTXOW_LbEDar",
        "outputId": "975962b9-ee57-49fe-db9c-e338c644a63a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1., -1.],\n",
              "        [ 1.,  1.]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out = tnsr.pow(2).sum()\n",
        "out.backward()\n",
        "tnsr.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7sFoX5sE_2Q",
        "outputId": "475c79c4-2d55-4d71-923f-4398ae544faa"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 2., -2.],\n",
              "        [ 2.,  2.]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpu = torch.cpu.current_device()\n",
        "cuda = torch.cuda.is_available()\n",
        "if cuda == True:\n",
        "  print('cuda is available')\n",
        "print('current device : ', torch.cuda.current_device())\n",
        "print('device count : ', torch.cuda.device_count())\n",
        "print('device name is : ', torch.cuda.get_device_name())\n",
        "device = torch.device('cuda:0')\n",
        "print('device properties : ', torch.cuda.get_device_properties(device))\n",
        "#print('Power drawn by GPU : ', torch.cuda.power_draw(device))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cv3pzJ51G_6Q",
        "outputId": "8fc12e2a-1e70-4a56-c340-537bb387c603"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda is available\n",
            "current device :  0\n",
            "device count :  1\n",
            "device name is :  Tesla T4\n",
            "device properties :  _CudaDeviceProperties(name='Tesla T4', major=7, minor=5, total_memory=15102MB, multi_processor_count=40)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpu\n",
        "gpu = torch.device('cuda:0')\n",
        "gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXxeLfj6Jbdj",
        "outputId": "996909ce-a39d-4638-d0c0-b6e737204c94"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Basic Math Operations**"
      ],
      "metadata": {
        "id": "vlWH0kzJuvgS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_a = torch.tensor([1,2,3,4])\n",
        "tensor_b = torch.tensor([4,5,6,7])\n",
        "\n",
        "print(torch.add(tensor_a, tensor_b))\n",
        "print(torch.mul(tensor_a , tensor_b))\n",
        "print(torch.divide(tensor_a , tensor_b))\n",
        "print(torch.remainder(tensor_b, tensor_a))\n",
        "print(torch.pow(tensor_a, tensor_b))"
      ],
      "metadata": {
        "id": "Ge6QiLAUKkaS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77273bed-61a4-42ec-a7e8-967ab4eb0222"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 5,  7,  9, 11])\n",
            "tensor([ 4, 10, 18, 28])\n",
            "tensor([0.2500, 0.4000, 0.5000, 0.5714])\n",
            "tensor([0, 1, 0, 3])\n",
            "tensor([    1,    32,   729, 16384])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tens = torch.tensor([12,4,7])\n",
        "tens\n",
        "tens.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLPVAGOlauGq",
        "outputId": "b6b7ff61-575a-44af-c5ea-42356598befc"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_tensor = torch.randn(3)\n",
        "print(my_tensor)\n",
        "my_tensor = torch.mul(my_tensor, 100)\n",
        "my_tensor = torch.abs(my_tensor)    # Get the absolute value\n",
        "# my_tensor = torch.mul(my_tensor, 100)\n",
        "# my_tensor\n",
        "print('Rounded values : ',torch.round(my_tensor))\n",
        "torch.max(my_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9patke57IvD",
        "outputId": "9ad15596-3af3-4880-c727-893239f2496c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.9271,  2.0423, -1.1030])\n",
            "Rounded values :  tensor([ 93., 204., 110.])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(204.2307)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prod_this = torch.tensor([1,2,3,4,5])\n",
        "torch.prod(prod_this)\n",
        "seven20 = torch.arange(1,7)\n",
        "seven20\n",
        "print(torch.prod(seven20))\n",
        "\n",
        "# count non-zero\n",
        "print(torch.count_nonzero(prod_this))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgxM1pYmDkl4",
        "outputId": "186e7490-bd12-40b2-e8ec-939096c9347b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(720)\n",
            "tensor(5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sort"
      ],
      "metadata": {
        "id": "ffVHuVXPE-15"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.sort(prod_this, descending=False)     #descending=False we can change it to True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmsYhcCkFA0_",
        "outputId": "39d9fc70-50c4-4492-efd3-13e390097c5b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.return_types.sort(\n",
              "values=tensor([1, 2, 3, 4, 5]),\n",
              "indices=tensor([0, 1, 2, 3, 4]))"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.tensor([1,2,3,4,5,6]).reshape(2,3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjasuAei1me5",
        "outputId": "2a6fc352-0d03-4ad9-9b87-cf1b4db0b00f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3],\n",
              "        [4, 5, 6]])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.get_device_properties(torch.cuda.get_device_name)\n",
        "\n",
        "torch.cuda.get_device_capability(torch.cuda.get_device_name)\n",
        "torch.cuda.is_available()\n",
        "torch.cuda.is_initialized()\n",
        "print('memory allocated : ',torch.cuda.memory_allocated())\n",
        "print('memory usage: ', torch.cuda.memory_cached)\n",
        "torch.cuda.power_draw"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "yGF-eb7qtFZR",
        "outputId": "cf681c53-7c2f-4b97-cfa1-40ce879c2847"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "memory allocated :  512\n",
            "memory usage:  <function memory_cached at 0x78f0f0be24d0>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function torch.cuda.power_draw(device: Union[torch.device, str, int, NoneType] = None) -> int>"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>torch.cuda.power_draw</b><br/>def power_draw(device: Optional[Union[Device, int]]=None) -&gt; int</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py</a>Return the average power draw of the GPU sensor in mW (MilliWatts)\n",
              "    over the past sample period as given by `nvidia-smi` for Fermi or newer fully supported devices.\n",
              "\n",
              "Args:\n",
              "    device (torch.device or int, optional): selected device. Returns\n",
              "        statistic for the current device, given by :func:`~torch.cuda.current_device`,\n",
              "        if :attr:`device` is ``None`` (default).\n",
              "\n",
              "Warning: Each sample period may be between 1 second and 1/6 second,\n",
              "depending on the product being queried.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 1125);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor(torch.rand(50))\n",
        "\n",
        "shape = torch.reshape(a, (5,10))\n",
        "shape.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhYdnPDFvH-H",
        "outputId": "33bbdf3f-ac04-43ac-b27c-cbf9b349b378"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-29-0d7fd5271b5f>:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  a = torch.tensor(torch.rand(50))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CPU**"
      ],
      "metadata": {
        "id": "66ay4-s70vNi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cpu.current_device()\n",
        "torch.cpu.device_count"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "raqqy_3j0yyK",
        "outputId": "7a69423e-c917-4e5d-9596-43584a8b8123"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function torch.cpu.device_count() -> int>"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>torch.cpu.device_count</b><br/>def device_count() -&gt; int</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/torch/cpu/__init__.py</a>Returns number of CPU devices (not cores). Always 1.\n",
              "\n",
              "N.B. This function only exists to facilitate device-agnostic code</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 148);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_arr = torch.tensor([[15,12],[12,8]])\n",
        "print(y_arr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEugj3VRJ-NC",
        "outputId": "ca4e5f2e-fbcc-4098-cdbd-12a714384abc"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[15, 12],\n",
            "        [12,  8]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor"
      ],
      "metadata": {
        "id": "LsdRQJvFlkMj"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download training data from open datasets.\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")\n",
        "\n",
        "# Download test data from open datasets.\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYnbGm0XloSa",
        "outputId": "133cb0a0-c147-430e-84b2-ea54e1f74684"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:02<00:00, 11314310.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 170970.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:01<00:00, 3088768.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 5197948.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "# Create data loaders.\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "for X, y in test_dataloader:\n",
        "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
        "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCSbFkvql4Fd",
        "outputId": "b9261406-4101-46d3-f591-4f92af0ca422"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
            "Shape of y: torch.Size([64]) torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating Models**"
      ],
      "metadata": {
        "id": "bnXQAjsQmCdT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get cpu, gpu or mps device for training.\n",
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "# Define model\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "model = NeuralNetwork().to(device)    #move to GPU\n",
        "print(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGhPFZ0gmDzj",
        "outputId": "27f77710-0e10-4334-f4e4-3a6a14735aed"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**!!! Pytorch Practice Session Covered all the necessary basic operations in Pytorch Library  !!!**"
      ],
      "metadata": {
        "id": "giAA-aybNEel"
      }
    }
  ]
}