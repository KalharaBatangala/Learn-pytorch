{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPKoFRdVE3EXg5fVKaQhlFd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KalharaBatangala/Learn-pytorch/blob/main/Learn_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xXlzAWrSHTRP"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pytorch basics**"
      ],
      "metadata": {
        "id": "2sJ9vu-yz14b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrkpTvX7Hhz2",
        "outputId": "c317f25e-3ec7-4ccb-b166-d4eb3b5f2e70"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.4.1+cu121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mylist = [[1,2,3],[4,5,6]]    # this is a typical python list.\n",
        "                              # Neither a numpy array nor a tensor\n",
        "\n",
        "#numpy array\n",
        "np1 = np.random.rand(3,5,5) # Random.rand no [] brackets\n",
        "np1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtJxsRTEHyGv",
        "outputId": "15e7a57f-23be-4ca3-88dc-5a593b9685c4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0.24350039, 0.89740057, 0.35552383, 0.27720022, 0.77343287],\n",
              "        [0.10789866, 0.97681907, 0.13911476, 0.89173613, 0.96833056],\n",
              "        [0.87446435, 0.60660533, 0.62303272, 0.95166338, 0.56783482],\n",
              "        [0.62556021, 0.14675165, 0.85685185, 0.49635456, 0.57783601],\n",
              "        [0.69038104, 0.59781319, 0.78913867, 0.90054322, 0.7989546 ]],\n",
              "\n",
              "       [[0.00330546, 0.16716051, 0.90094753, 0.92947013, 0.44530469],\n",
              "        [0.65742639, 0.10741696, 0.90692787, 0.37806293, 0.54514109],\n",
              "        [0.55105236, 0.91531478, 0.15486338, 0.41298972, 0.10870563],\n",
              "        [0.99157783, 0.13472489, 0.28314195, 0.41361577, 0.9308612 ],\n",
              "        [0.72747387, 0.69140607, 0.57102991, 0.69933895, 0.23755148]],\n",
              "\n",
              "       [[0.61571535, 0.52965727, 0.22669877, 0.55386192, 0.84645397],\n",
              "        [0.34332379, 0.2845847 , 0.2093059 , 0.8227076 , 0.46522213],\n",
              "        [0.89956596, 0.68683167, 0.83820936, 0.53468113, 0.41122383],\n",
              "        [0.67613136, 0.53895001, 0.97398826, 0.89348635, 0.80121024],\n",
              "        [0.74646966, 0.9843432 , 0.68200882, 0.38855562, 0.73762815]]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np2 = 100 * np.random.rand(2,3)\n",
        "np2 = np.array(np2, dtype=int)\n",
        "np2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRRXdPbDWP7I",
        "outputId": "2c09ab91-d34a-48b1-bafb-09b7533c6505"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[97, 56,  3],\n",
              "       [63, 11,  0]])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using ones and Zeros\n",
        "ones = np.ones([2,3], dtype=int)  # Must need [] brackets in ones & zeros.\n",
        "ones                              # dtype can be specified in np.ones and np.zeros"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwdPQUKc39nL",
        "outputId": "a4ef790e-2993-4095-a590-9ba1a7fb8ef9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 1, 1],\n",
              "       [1, 1, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np1.dtype)   # Random has no arguement as dtype\n",
        "                   # Therefore always dtype=float64 (default)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55E_HSgVKgV9",
        "outputId": "4af6e062-bd6b-492f-bc46-75bd91c86aa9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ar_ones = torch.ones(5)\n",
        "print(ar_ones)\n",
        "print('No. of elements : ', torch.numel(ar_ones))\n",
        "torch.is_tensor(ar_ones)    # check whethr a tensor\n",
        "torch.is_storage(ar_ones)   # not an storage - False\n",
        "torch.is_nonzero(ar_ones[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNaNusC5AzZ8",
        "outputId": "8f6e8ad2-761e-4b68-ee52-6d320e496d9f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1., 1., 1.])\n",
            "No. of elements :  5\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#torch.is_nonzero(ar_ones)\n",
        "# RuntimeError                              Traceback (most recent call last)\n",
        "# <ipython-input-30-011fd7f163f7> in <cell line: 1>()\n",
        "# ----> 1 torch.is_nonzero(ar_ones)\n",
        "\n",
        "# RuntimeError: Boolean value of Tensor with more than one value is ambiguous"
      ],
      "metadata": {
        "id": "Ti5JQX9HGDAb"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_2d = torch.rand(3,4)   # Doesn't matter whether [] is present or not in TENSOR\n",
        "tensor_2d\n",
        "\n",
        "tensor2d = torch.rand([3,4])\n",
        "print('tensor_2d\\n', tensor2d * 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUDXzbPEOXf5",
        "outputId": "4f1ea13f-8cd5-4056-d51a-7b61b0d8d112"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor_2d\n",
            " tensor([[9.2445, 5.5311, 8.9571, 2.4774],\n",
            "        [5.0873, 4.7398, 2.4970, 6.1052],\n",
            "        [3.8018, 9.3663, 9.7197, 4.0758]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testing = torch.tensor([1,2.,3],  requires_grad=True, device=torch.device('cpu'))\n",
        "threads = torch.get_num_threads()\n",
        "print('Number of threads :',threads)\n",
        "testing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yIMNUUeeQY5",
        "outputId": "3066d1a7-2ee0-46c0-aae1-ab5a333b9d09"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of threads : 1\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 2., 3.], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "check_grad = torch.is_grad_enabled()\n",
        "print(check_grad)\n",
        "torch.no_grad()\n",
        "print(torch.is_grad_enabled())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEdmsJqOgqkh",
        "outputId": "40d77df5-8ed3-49bd-e2de-48609af0fb5b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_3d = torch.zeros(2,3,4)\n",
        "print(tensor_3d.dtype)\n",
        "tensor_3d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KV6c9N_OuET",
        "outputId": "18570276-3203-418b-cbe8-a301c29cf9f1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float32\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a tensor out of numpy array\n",
        "mytensor = torch.tensor(np1)\n",
        "mytensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0p5zTqePijC",
        "outputId": "62da7d68-8f13-4ecf-c3ee-f9cfb0aae04b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.2435, 0.8974, 0.3555, 0.2772, 0.7734],\n",
              "         [0.1079, 0.9768, 0.1391, 0.8917, 0.9683],\n",
              "         [0.8745, 0.6066, 0.6230, 0.9517, 0.5678],\n",
              "         [0.6256, 0.1468, 0.8569, 0.4964, 0.5778],\n",
              "         [0.6904, 0.5978, 0.7891, 0.9005, 0.7990]],\n",
              "\n",
              "        [[0.0033, 0.1672, 0.9009, 0.9295, 0.4453],\n",
              "         [0.6574, 0.1074, 0.9069, 0.3781, 0.5451],\n",
              "         [0.5511, 0.9153, 0.1549, 0.4130, 0.1087],\n",
              "         [0.9916, 0.1347, 0.2831, 0.4136, 0.9309],\n",
              "         [0.7275, 0.6914, 0.5710, 0.6993, 0.2376]],\n",
              "\n",
              "        [[0.6157, 0.5297, 0.2267, 0.5539, 0.8465],\n",
              "         [0.3433, 0.2846, 0.2093, 0.8227, 0.4652],\n",
              "         [0.8996, 0.6868, 0.8382, 0.5347, 0.4112],\n",
              "         [0.6761, 0.5390, 0.9740, 0.8935, 0.8012],\n",
              "         [0.7465, 0.9843, 0.6820, 0.3886, 0.7376]]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a tensor with specific data type\n",
        "mytensor = torch.zeros([2,3],dtype=torch.int64)\n",
        "mytensor\n",
        "\n",
        "cuda0 = torch.device('cuda:0')\n",
        "print(mytensor)\n",
        "cuda0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-RM9tCwddrr",
        "outputId": "1a886d92-c4e0-4821-de71-e5c559c7a9bf"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 0, 0],\n",
            "        [0, 0, 0]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.ones([4,4], dtype=torch.float64, device=cuda0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYiZHJqJRSFt",
        "outputId": "dcad5986-4a4d-4e6c-c3e4-ef7cbf974e2f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.]], device='cuda:0', dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Content can be accessed and modified using slice and indexing"
      ],
      "metadata": {
        "id": "hAV3p6RrUuWY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "r = torch.tensor([[1,2,3], [4,5,6]])\n",
        "y = np.random.rand(2,3)\n",
        "print(r[1][0])\n",
        "print(y)\n",
        "print(y[1][1])\n",
        "z = torch.tensor(y)\n",
        "\n",
        "print(z[1][1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mMuWvHt0biq",
        "outputId": "a78bcaa1-1953-4fab-b249-3e58aec42bc0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(4)\n",
            "[[0.72190302 0.57379345 0.00941467]\n",
            " [0.83576679 0.5090462  0.50437538]]\n",
            "0.5090461961552345\n",
            "tensor(0.5090, dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "x = torch.tensor([[1,2,3], [4,5,6]])\n",
        "y = np.random.rand(2,3)\n",
        "print(x[1][0])\n",
        "print(y)\n",
        "print(y[1][1])\n",
        "z = torch.tensor(y)\n",
        "\n",
        "print(z[1][1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Iy7nGwEeTTf",
        "outputId": "7635b178-8d69-4c7b-edd9-f75910803326"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(4)\n",
            "[[0.61929098 0.14426551 0.73015281]\n",
            " [0.69639608 0.83669875 0.57916938]]\n",
            "0.8366987531326655\n",
            "tensor(0.8367, dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Torch.tensor.item() :  get a Python number from a tensor containing a **single value**"
      ],
      "metadata": {
        "id": "Yd4El915DagA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([[1]])\n",
        "x\n",
        "x.item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVllzgNJDdfa",
        "outputId": "c9d8fbe9-91d7-4b55-9c0e-64af594101db"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tnsr = torch.tensor([[1,-1],[1,1]],dtype=torch.float64, requires_grad=True)\n",
        "tnsr\n",
        "\n",
        "          # OR #\n",
        "tnsr = torch.tensor([[1.,-1.],[1.,1.]], requires_grad=True)\n",
        "tnsr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTXOW_LbEDar",
        "outputId": "d91ad616-395b-4d69-d022-9357499dce7d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1., -1.],\n",
              "        [ 1.,  1.]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out = tnsr.pow(2).sum()\n",
        "out.backward()\n",
        "tnsr.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7sFoX5sE_2Q",
        "outputId": "d72d6aa4-abda-4883-f2c0-c228491f70ca"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 2., -2.],\n",
              "        [ 2.,  2.]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpu = torch.cpu.current_device()\n",
        "cuda = torch.cuda.is_available()\n",
        "if cuda == True:\n",
        "  print('cuda is available')\n",
        "print('current device : ', torch.cuda.current_device())\n",
        "print('device count : ', torch.cuda.device_count())\n",
        "print('device name is : ', torch.cuda.get_device_name())\n",
        "device = torch.device('cuda:0')\n",
        "print('device properties : ', torch.cuda.get_device_properties(device))\n",
        "#print('Power drawn by GPU : ', torch.cuda.power_draw(device))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cv3pzJ51G_6Q",
        "outputId": "87a8c7fd-923a-4a3e-9d52-3b8b327879c0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda is available\n",
            "current device :  0\n",
            "device count :  1\n",
            "device name is :  Tesla T4\n",
            "device properties :  _CudaDeviceProperties(name='Tesla T4', major=7, minor=5, total_memory=15102MB, multi_processor_count=40)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpu\n",
        "gpu = torch.device('cuda:0')\n",
        "gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXxeLfj6Jbdj",
        "outputId": "b5b09e0b-28ee-4e41-fdc5-fd4f1fe09fce"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Basic Math Operations**"
      ],
      "metadata": {
        "id": "vlWH0kzJuvgS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_a = torch.tensor([1,2,3,4])\n",
        "tensor_b = torch.tensor([4,5,6,7])\n",
        "\n",
        "print(torch.add(tensor_a, tensor_b))\n",
        "print(torch.mul(tensor_a , tensor_b))\n",
        "print(torch.divide(tensor_a , tensor_b))\n",
        "print(torch.remainder(tensor_b, tensor_a))\n",
        "print(torch.pow(tensor_a, tensor_b))"
      ],
      "metadata": {
        "id": "Ge6QiLAUKkaS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "948ccdd3-22b1-4626-dd0f-39844ef77fa4"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 5,  7,  9, 11])\n",
            "tensor([ 4, 10, 18, 28])\n",
            "tensor([0.2500, 0.4000, 0.5000, 0.5714])\n",
            "tensor([0, 1, 0, 3])\n",
            "tensor([    1,    32,   729, 16384])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tens = torch.tensor([12,4,7])\n",
        "tens\n",
        "tens.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLPVAGOlauGq",
        "outputId": "2e025c86-dd17-4320-8342-f08a6a5c8ab9"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_tensor = torch.randn(3)\n",
        "print(my_tensor)\n",
        "my_tensor = torch.mul(my_tensor, 100)\n",
        "my_tensor = torch.abs(my_tensor)    # Get the absolute value\n",
        "# my_tensor = torch.mul(my_tensor, 100)\n",
        "# my_tensor\n",
        "print('Rounded values : ',torch.round(my_tensor))\n",
        "torch.max(my_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9patke57IvD",
        "outputId": "96d2abf1-424d-420a-da03-26e041277da1"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.2470, -0.1639, -1.1384])\n",
            "Rounded values :  tensor([ 25.,  16., 114.])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(113.8373)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prod_this = torch.tensor([1,2,3,4,5])\n",
        "torch.prod(prod_this)\n",
        "seven20 = torch.arange(1,7)\n",
        "seven20\n",
        "print(torch.prod(seven20))\n",
        "\n",
        "# count non-zero\n",
        "print(torch.count_nonzero(prod_this))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgxM1pYmDkl4",
        "outputId": "658092f4-4feb-443c-a6f4-ccdedeeb0cd5"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(720)\n",
            "tensor(5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sort"
      ],
      "metadata": {
        "id": "ffVHuVXPE-15"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.sort(prod_this, descending=False)     #descending=False we can change it to True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmsYhcCkFA0_",
        "outputId": "91fd677b-0b9f-43a0-dcf8-be5869121ef4"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.return_types.sort(\n",
              "values=tensor([1, 2, 3, 4, 5]),\n",
              "indices=tensor([0, 1, 2, 3, 4]))"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.tensor([1,2,3,4,5,6]).reshape(2,3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjasuAei1me5",
        "outputId": "8e7aba0f-656d-466c-c334-51e4c9f8a218"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3],\n",
              "        [4, 5, 6]])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.get_device_properties(torch.cuda.get_device_name)\n",
        "\n",
        "torch.cuda.get_device_capability(torch.cuda.get_device_name)\n",
        "torch.cuda.is_available()\n",
        "torch.cuda.is_initialized()\n",
        "print('memory allocated : ',torch.cuda.memory_allocated())\n",
        "print('memory usage: ', torch.cuda.memory_cached)\n",
        "torch.cuda.power_draw"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "yGF-eb7qtFZR",
        "outputId": "db1e9184-f7b8-4465-d024-92ccfa8de316"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "memory allocated :  512\n",
            "memory usage:  <function memory_cached at 0x7aca0c0d24d0>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function torch.cuda.power_draw(device: Union[torch.device, str, int, NoneType] = None) -> int>"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>torch.cuda.power_draw</b><br/>def power_draw(device: Optional[Union[Device, int]]=None) -&gt; int</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py</a>Return the average power draw of the GPU sensor in mW (MilliWatts)\n",
              "    over the past sample period as given by `nvidia-smi` for Fermi or newer fully supported devices.\n",
              "\n",
              "Args:\n",
              "    device (torch.device or int, optional): selected device. Returns\n",
              "        statistic for the current device, given by :func:`~torch.cuda.current_device`,\n",
              "        if :attr:`device` is ``None`` (default).\n",
              "\n",
              "Warning: Each sample period may be between 1 second and 1/6 second,\n",
              "depending on the product being queried.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 1125);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor(torch.rand(50))\n",
        "\n",
        "shape = torch.reshape(a, (5,10))\n",
        "shape.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhYdnPDFvH-H",
        "outputId": "5ba22e48-3673-44c3-e6aa-4d0303e3b19d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-29-0d7fd5271b5f>:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  a = torch.tensor(torch.rand(50))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CPU**"
      ],
      "metadata": {
        "id": "66ay4-s70vNi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cpu.current_device()\n",
        "torch.cpu.device_count"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "raqqy_3j0yyK",
        "outputId": "e900c660-78c6-47bd-c6bd-26e00d1dbd9b"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function torch.cpu.device_count() -> int>"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>torch.cpu.device_count</b><br/>def device_count() -&gt; int</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/torch/cpu/__init__.py</a>Returns number of CPU devices (not cores). Always 1.\n",
              "\n",
              "N.B. This function only exists to facilitate device-agnostic code</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 148);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_arr = torch.tensor([[15,12],[12,8]])\n",
        "print(y_arr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEugj3VRJ-NC",
        "outputId": "4f088d1a-b789-461b-c718-076b69654e82"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[15, 12],\n",
            "        [12,  8]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor"
      ],
      "metadata": {
        "id": "LsdRQJvFlkMj"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download training data from open datasets.\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")\n",
        "\n",
        "# Download test data from open datasets.\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYnbGm0XloSa",
        "outputId": "95e9813a-0064-4eeb-d0a7-aac008aa3652"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:12<00:00, 2105479.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 178648.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:01<00:00, 3220046.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 21463496.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "# Create data loaders.\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "for X, y in test_dataloader:\n",
        "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
        "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCSbFkvql4Fd",
        "outputId": "92b2bded-f5af-4abf-d678-8504d9da7611"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
            "Shape of y: torch.Size([64]) torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating Models**"
      ],
      "metadata": {
        "id": "bnXQAjsQmCdT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get cpu, gpu or mps device for training.\n",
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "# Define model\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "model = NeuralNetwork().to(device)    #move to GPU\n",
        "print(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGhPFZ0gmDzj",
        "outputId": "4448d733-d07f-4fe5-a260-31ff87447f56"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**!!! Pytorch Practice Session Covered all the necessary basic operations in Pytorch Library  !!!**"
      ],
      "metadata": {
        "id": "giAA-aybNEel"
      }
    }
  ]
}